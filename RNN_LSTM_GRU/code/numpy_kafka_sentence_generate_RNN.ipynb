{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport os\nprint(os.listdir(\"../input\"))",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['kafka.txt']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open('../input/kafka.txt','r') as f:\n    text = f.read()\nprint(type(text))",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'str'>\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "189e5a4bbb897d0fa117d0d1f601fdf609d47201"
      },
      "cell_type": "code",
      "source": "data = open('../input/kafka.txt','r').read()\ndata[:100]",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "'\\ufeffOne morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed i'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1eb83f8ce6f0dd75915a4def784514f175809c55"
      },
      "cell_type": "code",
      "source": "chars = sorted(list(set(data)))\ndata_size = len(data)\nvocab_size = len(chars)\nprint('data_size: ',data_size, '\\nvocab_size: ',vocab_size)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "data_size:  118561 \nvocab_size:  63\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "054fa369ac694726f95264a7de806ed3518ab0ab"
      },
      "cell_type": "code",
      "source": "# char_to_idx = {char,idx for idx,char in enumerate(chars)}\nchar_to_idx = { char:idx for idx,char in enumerate(chars)}\nidx_to_char = { idx:char for idx,char in enumerate(chars)}\nprint('char_to_idx: ',char_to_idx, '\\nidx_to_char: ',idx_to_char)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "char_to_idx:  {'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'Q': 28, 'S': 29, 'T': 30, 'U': 31, 'V': 32, 'W': 33, 'Y': 34, 'a': 35, 'b': 36, 'c': 37, 'd': 38, 'e': 39, 'f': 40, 'g': 41, 'h': 42, 'i': 43, 'j': 44, 'k': 45, 'l': 46, 'm': 47, 'n': 48, 'o': 49, 'p': 50, 'q': 51, 'r': 52, 's': 53, 't': 54, 'u': 55, 'v': 56, 'w': 57, 'x': 58, 'y': 59, 'z': 60, 'ç': 61, '\\ufeff': 62} \nidx_to_char:  {0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'L', 24: 'M', 25: 'N', 26: 'O', 27: 'P', 28: 'Q', 29: 'S', 30: 'T', 31: 'U', 32: 'V', 33: 'W', 34: 'Y', 35: 'a', 36: 'b', 37: 'c', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h', 43: 'i', 44: 'j', 45: 'k', 46: 'l', 47: 'm', 48: 'n', 49: 'o', 50: 'p', 51: 'q', 52: 'r', 53: 's', 54: 't', 55: 'u', 56: 'v', 57: 'w', 58: 'x', 59: 'y', 60: 'z', 61: 'ç', 62: '\\ufeff'}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "34c9e6d40e87b7bab52b48e3cecf75920cdbb66d"
      },
      "cell_type": "markdown",
      "source": "Hyperparameters"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cea8a1e61e269346815143df7ca94841695f2947"
      },
      "cell_type": "code",
      "source": "hidden_size = 100\nseq_length = 25\nlearning_rate = 1e-1\n\nWxh = np.random.randn(hidden_size,vocab_size) * 0.01 # weight matrix input x->hidden\nWhh = np.random.randn(hidden_size,hidden_size) * 0.01 # weight matrix hidden->hidden/memory\nWhy = np.random.randn(vocab_size,hidden_size) * 0.01 # weight matrix hidden->output y\nbh = np.zeros((hidden_size,1)) # bias of hidden\nby = np.zeros((vocab_size,1)) # bias of output y",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd45fb9ee6a1186150b7320277f94b6e6d810e60"
      },
      "cell_type": "code",
      "source": "def lossFunc(inputs, targets, hprev):\n    # inputs: (25, 63, 1), a sentence, contains 25 words, which word has a (vocab,1) shape vector\n    # outputs: (25, 63, 1), the label of input which has the same shape of input\n    # hprev: the previous state of hodden layer / memory\n    xs, hs, ys, ps = {}, {}, {}, {} # state of x, hidden, y, p(probability of y)\n    hs[-1] = np.copy(hprev) # init previous state of hidden/memory in dict {-1:hprev}\n    loss = 0\n    \n    # Forward\n    for t in range(len(inputs)): # idx of each word in input sentence / each time step\n        xs[t] = np.zeros((vocab_size,1)) \n        xs[t][inputs[t]] = 1 # t-th word's vector's t-th element = 1 \n        hs[t] = np.tanh(np.dot(Wxh,xs[t]) + np.dot(Whh,hs[t-1]+bh))\n        ys[t] = np.dot(Why, hs[t])+by\n        ps[t] = np.exp(ys[t]) / (np.sum(np.exp(ys[t]))) # ps[t] 向量的每个元素对应词汇表中每个单词的概率\n        loss += -np.log(ps[t][targets[t],0]) # ps[t][targets[t]]选择出label对应盖茨的概率, 0 ???\n    \n    # Backward\n    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n    dhnext = np.zeros_like(hs[0]) # hs[3] also Ok, cuz each vector has same shape\n    for t in reversed(range(len(inputs))):\n        dy = np.copy(ps[t]) # back softmax-crossentropy\n        dy[targets[t]] -= 1\n        dWhy += np.dot(dy, hs[t].T)\n        dby += dy\n        dh = np.dot(Why.T, dy) + dhnext # if variable being inited above, use +=, else =\n        dhraw = (1-hs[t]*hs[t]) * dh \n        dbh += dhraw\n        dWhh += np.dot(dhraw, hs[t-1].T)\n        dWxh += np.dot(dhraw, xs[t].T)\n        dhnext += np.dot(Whh.T, dhraw)\n    \n    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n        np.clip(dparam, -5, 5, out=dparam) # eliminate gradient vanishing, exploding\n        \n    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1] \n    #  hs[len(inputs)-1]: last second hidden state/memory of this input sentence",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9dd92e2282ccd1869a63045ecf3df879b766e9a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c7da1eb17b2657d74b210f1bdbb50caad978b543"
      },
      "cell_type": "markdown",
      "source": "- dict\n```python\na = {}\na[-1] = 3\na['-2']=1\n```\n```python\n{-1: 3, '-2': 1}\n```\n\n- reversed\n```python\nfor i in reversed(range(3)):\n    print(i)\n```\n```python\n2 1 0\n```\n\n- np.clip(a, a_min, a_max, out=None)\n```python\n\"\"\"\nSignature: np.clip(a, a_min, a_max, out=None)\nDocstring: Clip (limit) the values in an array.\n\"\"\"\na = np.array([i for i in range(10)])\n# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nnp.clip(a, 3, 7, out=a) # output a \na # array([3, 3, 3, 3, 4, 5, 6, 7, 7, 7])\n```"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16701864198f6f97e441c62168d8d6034befdf2b"
      },
      "cell_type": "code",
      "source": "def sample(h, seed_ix, n):\n    # h: last hidden state / memory\n    # seed_idx: the idx of the first word/char of the sentence we want to generate in corpus\n    # n: the length of the sentence we want to generate, how many characters to predict\n    \n    # create the first word's/char's vector\n    x = np.zeros((vocab_size,1))\n    x[seed_ix] = 1\n    ixes = [] # resotre the idx of words/chars of the sentence\n    \n    for t in range(n):\n        h = np.tanh(np.dot(Wxh,x) + (np.dot(Whh, h)+bh))\n        y = np.dot(Why, h)+by\n        p = np.exp(y) / np.sum(np.exp(y))\n        # select the biggest element? NO!NO! select randomly\n        ix = np.random.choice(range(vocab_size), p=p.ravel())\n        x = np.zeros((vocab_size,1))\n        x[ix] = 1\n        ixes.append(ix)\n    txt = ''.join(idx_to_char[ix] for ix in ixes)\n    print('-----\\n',txt,'\\n-----')\n    \nhprev = np.zeros((hidden_size,1))\nsample(hprev,char_to_idx['a'],100)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "-----\n t(UJLsLUzH)o(diTSd-eD\nHP﻿NlOCnnExTO-zeHT \"yYVP?-:SM(tt!Min()Hgul,YvW)IfF-hTG!m ?AJl-Ww(DmQtlW.yLIm!i \n-----\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c98bae1523bb5cba5ac3222a1e4a28b3501a414e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "69048582eade26f578fe2a9412c20a6786e8c741"
      },
      "cell_type": "markdown",
      "source": "- array.eval()\n\n```python\na = np.array([[1,2,3],[4,5,6]])\na_exp = np.exp(a) / np.sum(np.exp(a))\n=>\n# array([[0.00426978, 0.01160646, 0.03154963],\n#            [0.08576079, 0.23312201, 0.63369132]])\na_exp.ravel()\n=>\n# array([0.00426978, 0.01160646, 0.03154963, 0.08576079, 0.23312201,\n#        0.63369132])\n```\n- np.random.choice()\n```python\n# select a element randomly\nnp.random.choice(range(6),p=a_exp.ravel()) \n# p means probability, or else, ValueError: probabilities do not sum to 1\n```"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "549ddc9de7a57b1be706e16dc2968e47f165e550"
      },
      "cell_type": "code",
      "source": "p = 0\ninputs = [char_to_idx[i] for i in data[p:p+seq_length]]\ntargets = [char_to_idx[i] for i in data[p+1:p+1+seq_length]]\nprint('inputs: ',inputs,'\\ntargets: ',targets)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "inputs:  [62, 26, 48, 39, 1, 47, 49, 52, 48, 43, 48, 41, 7, 1, 57, 42, 39, 48, 1, 19, 52, 39, 41, 49, 52] \ntargets:  [26, 48, 39, 1, 47, 49, 52, 48, 43, 48, 41, 7, 1, 57, 42, 39, 48, 1, 19, 52, 39, 41, 49, 52, 1]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd4a3c244e691d0f29ab794d8b1ec19d38327ca5"
      },
      "cell_type": "code",
      "source": "n,p = 0, 0\n# memory variables for Adagrad\nmWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\nmbh, mby = np.zeros_like(bh), np.zeros_like(by)\n\nsmooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0                \n\nwhile n <= 1000 * 100:\n    if p+1+seq_length >= len(data) or n ==0:\n        hprev = np.zeros((hidden_size,1))\n        p = 0\n        \n    inputs = [char_to_idx[ch] for ch in data[p:p+seq_length]]\n    targets = [char_to_idx[ch] for ch in data[p+1:p+seq_length+1]]\n\n    # forward seq_length characters through the net and fetch gradient                                                                                                                          \n    loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFunc(inputs, targets, hprev)\n    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n\n    # sample from the model now and then                                                                                                                                                        \n    if n % 1000 == 0:\n        print('iter: {} - loss: {}'.format(n, smooth_loss)) # print progress\n        sample(hprev, inputs[0], 200)\n\n    # perform parameter update with Adagrad                                                                                                                                                     \n    for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n                                  [dWxh, dWhh, dWhy, dbh, dby],\n                                  [mWxh, mWhh, mWhy, mbh, mby]):\n        mem += dparam * dparam\n        param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update       \n    \n    p += seq_length\n    n += 1\n",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "iter: 0 - loss: 103.57836588466915\n-----\n UGDGmAywT\nçG\"iSq',FxpvjHQtDEB WQCW;xvFfoH Ez,YLGw?Pmd(E.HYs?uASPbiBb(tIsçxwurYTPQE)FWfb)axAx(fkAh 'Mpmbb(JnWtCL\"GVIuSekY!bS\"rHb?oDQçcnT?huGDgçPaNnapA-IV,Ckt  F VnVTpfSUjocO?ooABOBjncWIvVjDYtTS:\"DFvN-m \n-----\niter: 1000 - loss: 86.70338140933758\n-----\n llhinturhoute' t hapao e c iipa lwhr vn isgto ghn fe; tisesctre Bvw,n fOgerds taatlc olieudet hhk wpcht waee k t mf ; rfd esg   t e ctk cyoaatd nhacjA a yeo enn aw s s lOht \"sd k n o y haib at ornales \n-----\niter: 2000 - loss: 77.61935223673632\n-----\n ln: tn xwaay e.he ,rlahiahm sianio. slaeBhanPw ibsn thTecY hide y oiro e ne n!doum. ay lfI g he iwenN 'owwhirqS pInrat psoc sf , tf thher n, to-ars be, thrdl ee'lf tylvNd ish y smd o zThv wfhlgrf asnu \n-----\niter: 3000 - loss: 71.88834019541443\n-----\n hhls aimehabw aay.f txIitxpendere ndufehnd eojiwhnutele frady toy (kh w he eimnieeheyiouia ed wef le lgoa hi drel'anth hm t osibhd wiusae;seer t, Fra t maoN,elag hoocheSrneeheoor ainliashoruQ,buaerd-o \n-----\niter: 4000 - loss: 68.96677163595349\n-----\n ct o?rifatohalçg aast mhergLutU . whnyuws ouribeaiisthlee cot Oia sritIiairua cfOn. onYie tahithe ySs s wat, ase isYeicg ashor te see ne. ne htot tihey?acevemheannHe bitiicsueag hs utem heigit rlauano \n-----\niter: 5000 - loss: 72.01047530489933\n-----\n itinc oaI.tain m sdc eooomhvtnfhheogwhra. naa fatwnhmpa.tthd,ddohdBrlGnyopbmoithaaahhta aohft hdoiaroaaa.toiaAiaaa fWayohpkioGhaptt  tmikoit Tansht adtsihbfvmtctdawkiaigrPhigt hoeht oi a abh piNar tmk \n-----\niter: 6000 - loss: 71.64534753553463\n-----\n sdand vodhe noryitte l ntiçt bdehyne sdrithy slewa blCdne vgtothlsps  ri wawf ,. n tF,l oon aas t nl eotws stoiamyd fono\neohtaakelie edye m inan pn heataa to wived ci slwt'xto ssogis wuthed o\nFs (Ehit \n-----\niter: 7000 - loss: 69.3917998282773\n-----\n  ss dichehe uicsrnd senit rhere lcntabnd wghe tonfntrrist ps ss ruts neohimeeawlt ashawhe sg yct w.- rd nw,nTld sonnhale thans clonoooidu pewnd ieulaishidheisos taiiathlahe whd aaoufmsofit stheh ihadh \n-----\niter: 8000 - loss: 68.0307598780527\n-----\n he wlgtr afxde cbiheh d she he anthe whabt tocbhet wsoaiakat f ld slt s at,rdohpnduGhe shiatoulehcehrrl wt bsg git te vidlohedgunndllistgfouGnaay t baaaong the wheognkenusthe herastd Ghertgd vehawufev \n-----\niter: 9000 - loss: 69.4230109475471\n-----\n d og stt thirlk y o s aGi  naotfe-Qdocl .dFoliFoeashGtxpr uttr-rweb laftbGxhuwokyntDeodorto.v\"Gstuoohe uhd  eldthyoaefLfir tethMbia n in gsspedr ut tqthc r ds ,.tttidhooafowhaatte pa vnnd elchireoh s  \n-----\niter: 10000 - loss: 71.48795918578153\n-----\n r,. n usa l,rbGgn cir hmesth aua rmtjy gh enerty of, meuf hlnlcl  htdieioee.hwohho hdplobonez ceuq slsl hegei\"ntafy d uWr\"ihipetbl wyiee  h smnpseihouqmftis tnte,rgIr sor! rhaunee tps tef eorhpotlbshi \n-----\niter: 11000 - loss: 72.3132992929062\n-----\n mlppnhou oheemnhelccewrrur tounkhnlesthen ou sahu cd\naso tveeehk t ntr hthhoaegh-  eepgos th oy s   nt ahowsret,yeahe arelras trisgun;uaouthi!hnnm Heahon slohe hu ny,up,s om aaohets sithelatashiwtm'\"e \n-----\niter: 12000 - loss: 70.51114511350315\n-----\n  d wl eh plvoke ver e se r ibabuy eset. fer  od herreoo ahttpoee litnoeronrwdewn b pr,g,e e heuut o doo tre eeiGhn thasthrr  temfohd o ki: tkrouehtc cer pl. rpoe,oueoe o sgee ahem are lerrpty n asvoaf \n-----\niter: 13000 - loss: 70.11787619278927\n-----\n s s rr rr'nt tin tv ri ohianrt﻿zaEire  nriwken ct Q﻿?old Uet origtnrhdçd wun oisese tv i-ghehtorelntlvnsçhe!ese dshelG Ah nnn Içg aegr s se tt citr sr nosre ce t e tesd,l so d olinh rih,r init gg rh,i \n-----\niter: 14000 - loss: 69.88692145900832\n-----\n he .heaitohçnhnaif ss rt tetlemtledç corrte, riwoahae. igseeee inThe oc Tiatr﻿Oo  Ihes﻿e r theee imemGue waormefhe lererasioe bee tim ter  ter  hrihe m ohekaheweomy.om moeme\nmBf'rGhe Be wairec had eMo \n-----\niter: 15000 - loss: 70.56179777152511\n-----\n segitai oarenTsr ili ,o oaveeulehesrdouaout-thenxsgaotuts'dtmirea otr railaatpmwiotsrethe rtonpfecfnrr hitihenrouso h aotuny, ,o ud. iokm fue tohie ywtheerihioi rhe e inn'prsdegoootele h aotowuost tii \n-----\niter: 16000 - loss: 70.41867111555882\n-----\n tao: wawlhe ahiu'owonzhiair,,a   snishl rsladhied hbweti if egi\nmevelec'g mhero silterl ted s mis tyhlr bgdgluoe y nt\nnrr gtocoGytrhihat eNm ne l m,oea hE,ve Gqn ilk\niayçn asoitasrmhis le m e  giIwoeV \n-----\niter: 17000 - loss: 71.24988706836628\n-----\n ;idindinetr o the.reç  shgle u d oemyd lyd e  n ceua G fhoems  aloçgsooitsodithaan de uohve t nlrewmp'gv  on oaudveu rio bTthhthegeyw   ethimm ; ltkftolac  lhhw stdpnfiosvuedOnahracomwu the fet geioc  \n-----\niter: 18000 - loss: 71.33248199144468\n-----\n at ygn toj hueGthdt rglfilta hleley .i  dtsal  ia uouarueo  heBoaminro l t f bdrthu o , e f r nb sbhohad  an sc t t nn ryirbd  todo\noneta; heestcl\nvoltcdo wiprennenhchoshaertonl bntu t' nrpeeklhioehev \n-----\niter: 19000 - loss: 71.71601838717595\n-----\n  gosl tohseiaekvleytefr tdo npe is yovs et ph 'ohegohdeuHheDuit ue iwtn t'owheermmcee- lss tieleeo edalisameyswsl cis. wS, asnt oe wolke aga lihet mrichiemeoeed  ne shod dhae usalbtNdre urs t whtytlet \n-----\niter: 20000 - loss: 72.01088287093299\n-----\n er ro s oig q er rsattt s th rmn rst cHed ee Y eum tilre  o B\" tttisg ldase eneoit dyhtnas kE T leneifaneortohie p rl nn\" tl  mhe;nrh thero ateofpini, kss ns s yinnt.tiwtrals Ty ue  hsy ws, sctwStrer  \n-----\niter: 21000 - loss: 70.89669502963083\n-----\n ethihs,ret khonm riuhn Nhnmaouwuhekonbamucecid, oa tha rerud re ntiuutth nukos psd t f h sc( inf ogd wetHheeheisnW,eme bolafe alm srse, fp ibefy Td  ate ooroshe s  dde A itro naae otue'he p s e be t f \n-----\niter: 22000 - loss: 70.14153517326794\n-----\n eeisihat?pnhoo, oaaoyellf gSrtrs dan ,sd  ,han s t  jtaen soecwe ie  faw ?he orrH. G e eis itdl bea hiipsoteowye hieeme ddenh a,.eyynt Wse. dd is,ereaptes s thlyIe ww ekahes Hhah s. ibrt ferumelouorso \n-----\niter: 23000 - loss: 69.94987538710184\n-----\n ouhe apwrntst cuxinrr p H eolehvidep tt\"hee \"tiukoa.ihawbhe sdo lvaag ps e kerano islheoileranroohe bp' wsyot yt thtuns d wtervesisy m\"e od t, hipttsethea i t ashe ehieoeerc tlieorern  g um  bsGin thn \n-----\niter: 24000 - loss: 70.74926856332958\n-----\n  da biln vo\nhig itth cvem.yt asrtthe e?  hetcde w d  dI eedl a leetin and euhordklenoibTnele reda, oo eftornoe hvid seeesise pe a eutnht  fhew'  t e t io,y taoyt wedierite\",o tulioh thif lf o faikd d  \n-----\niter: 25000 - loss: 70.73025212657943\n-----\n eelwl inh  mecbisy lor\"deoe h theen eghfnr so piibheanleicn . foet  th rilnr se te c.tat te mhaon ad Btg her vedeow bn ihsu Dt haa ererr yhanae ho t adlotor dafehemale t there.ge viy ss .ir ehe s e in \n-----\niter: 26000 - loss: 69.94934912967196\n-----\n o hedh'aermrl;hiy\nyuheces iel, t eaaai.vm snto  uot y tebleohdueoee heihth lye fttowd whs n b. onesiaHhe tieh c t e, othe oraad sud e  lqln y loehk heok te o op, e  latd rmruhe dd , hi eoie t wh,se, o \n-----\niter: 27000 - loss: 70.16973063909255\n-----\n oloeot   alocoueo. tae mal rsc l f s c naheotS bninis n  e th rl iaeofut tu uchernd ehoer sbhe ehormh k in ofhdd Orne  h sict d  asifnitoilrhepind bhehe meeiI ont easprsa  g ilaleto usai st  l ihauthe \n-----\niter: 28000 - loss: 69.9788017756711\n-----\n at tppet oe ell vt, win feiasmtte eh c our ritthay ee te t-aSwdt t w arh nSmmGr chedsiuoc eeuthac aewe  ndehed al  remo h, nnl sC esin ritrtcitalpihid nuSemn,t n 'e agaseitmdeorhe eeud hirtf ar o at r \n-----\niter: 29000 - loss: 70.71833659553364\n-----\n  t nwo aiis is acro hen rebh s tol ad nheas ,  aocimyor mun se eeen tr rensle da tfm id rasinar r ss be bea ea rdet nhede au h  hea  b  itv tpe tte n hedseiHyto e anbe do.icend i\"g k a) inasi fma  oew \n-----\niter: 30000 - loss: 70.8348805890229\n-----\n mreigutn snt toiy nut re nhe iwinlwimo d swbtthonogifopareilmtorne srcanggo w wtsyegehmt ome he s eohveG a.  velatn  wher nsah k hd the iusepwkito une akff incer  powof o lh vee muohee s oaoocaen mowc \n-----\niter: 31000 - loss: 70.52904571470324\n-----\n s ssttmrsrtguh n hyaelaitte howe wm htrernpcdyWffis oofcegtootlicinottsg ntkmed oofiaepb iufepen e lhwtuthp mtsonviteheobs,utgkgai etpc d frihy hogmitd toir rd l h ros  lhotin otr hf   etenha nce rnnd \n-----\niter: 32000 - loss: 70.32643002447517\n-----\n nstaf aifManyeetoalhe rsean us ah s c snteksdlm Hta ioosetfe  d tg d orneon  fhs  kdior heheeheanomepe heoa heas iisy  onrisn ufnxgiofyi he tup frg,, hseqsi enlheaeomiedi siowa   eereeiuomeeetgellahie \n-----\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "iter: 33000 - loss: 71.15779785181853\n-----\n wotdad ako rhevr hnherve asp therege-tf whek f  d   aibeb h b!pbteG beheah  tli.emdnh etinhe Gh e\" bamSsb teit ty cucentulewshasimoh n  s  ttdh wen \"m r t ttios, ts le n tr hpya himiSt et bsr ighhpro! \n-----\niter: 34000 - loss: 71.75341723184114\n-----\n e owlwshe.in re gy emwann nM tte ate iit thaeerr'  ioheihed y reeer; cin inse e uv  ll o tile uo e da\nSke beitlyeds lsgIeeele.diiin\n na naicmd heaegrett ? tniusey o   l py,ecohesheuthe iariohee\"ileefa \n-----\niter: 35000 - loss: 71.2354956869876\n-----\n  Ueluwpadddey    eulrrisf see  l l wtbaeh i .ottnoed    ln s treha oh  tt boshehi th ntdetue; f tn kth,ineroe  r o ndth s l  he\"thvco thlnd hit mp aneed,  n, brwwmf eld e  ghetg h hel  rt nttac Be o(M \n-----\niter: 36000 - loss: 70.7154313549855\n-----\n ln whe  sf cwmek :uoooewitt,wseor pheath h.elenepothhi  f aet, antfopgsn t  ehianaf e w b une heoa cli  h tn andetee J e me wginae hets   \" s.ab msheiu tr ta ns,er)av e b  ts ewiheoy attlsenro c he r  \n-----\niter: 37000 - loss: 70.69216857688897\n-----\n g. cdmn ﻿rlll trekj a Iaanu p Ss  d,to  ri  biaoeabienne nci  th c s etse onah  i wteet aeeeehe sit headhe bhehe h  g meirotseimtg a u  wdenne,rsiet   y  d   n e nme r  uw tre ek g is.eh n npeau T t h \n-----\niter: 38000 - loss: 70.9951907377714\n-----\n eaedehiwlebHeetghv uomae ne tohe a ptnpreoisu eo n ffe,linhe xi lerueyeeU. !yo s ma  in  o hettdeeaceve ah afaGsug w l ho ano  n teteuief t tolit  o  wr  tnnn deh utt 'tm, wle ehedevr? wsttsatye  bs a \n-----\niter: 39000 - loss: 71.88421531415472\n-----\n o  e rensr.,tahe t ;sctclthothe ne eesroe Ielo ms d leneeg him V ossn sflin ihin yetiuap e ta wrahepab  l a er. d h hshawe Gt tdoeuaosac he cb\natneosatttne nhn feiohdigosder gn n yszeit pheeld ee hy x \n-----\niter: 40000 - loss: 70.39369072181991\n-----\n eve HeOsexee uyotowinayewut.E t t WaaadrtiAhimdnrerthentno kheositaladeleseGs ouisaoeuisos t   mheeraheee hoeohe.fhrm\nd h un ine roh af r leonanadeebe timu meesmps   es lvnau nip he r amcs dheOri cihe \n-----\niter: 41000 - loss: 69.61592085808107\n-----\n sle lnoclrcosisy at haur d o,ceo o v hekpvoorem nba re he sd  Gh letieahsot er  b tm r . id lfhe he swthoiwe heoioyl-emurhel m'at ehysru telthe  in m Ete te orb st,esoalviwecheld egniol roa w a  s.dow \n-----\niter: 42000 - loss: 69.42042978386\n-----\n we he ens fhe'ode'ohi cari \ntoray henegis aaosd swe ahe e t adenyekostonhem s deanoet horisle sf.   macejucopouse, eehe,lhemsuui eotaoalp mthe a gyll foat d seeaedwasmla w ,e seakhilihe herd nirshk se \n-----\niter: 43000 - loss: 70.10167804668916\n-----\n aleokehe oh cestgec t t h had lt e -eeys s\"set meher sntoil iu'ne fonir areitu nide bo ler re fe ofiqd  iaeiri. he he tho h ie a f j   hil oe eene ho -e liiod e? e pios tid tf itewIos her en ven weire \n-----\niter: 44000 - loss: 70.38731087248054\n-----\n uatfgfeegheto we c.dlecSeheetapotl tnnaoateaeiea  edk as) w ead  oscwo vierhogesierubi ne 'n d cdor sG aon e alive saG mhet  mi r reohifr os nn tr oir hi tooeeli ,l veted  tao or , reths rwatwee su nn \n-----\niter: 45000 - loss: 69.52459117135291\n-----\n he atinleeu he  \"Igo haihihezrehef ,sa nledteee her sf b s tTin tattea  coree nl  e wa t e  sthe sheweenai lnektotwwecnie m  o;﻿eleentne  c gi n testheolioeldoe ,d noddo  ed okherehetngs  winncou  nal \n-----\niter: 46000 - loss: 69.45153126415218\n-----\n be lt olge abeeedeousg wte whe;ed \nuh heoe on oedonldicbsurie w,ee heer nveurseer; o liii   the 'n marroatinteiaiihirs greg car ut Ao h Iuhaeeeeehecbuhe cec seier herddof, himeAheee  ;at thetif h tham \n-----\niter: 47000 - loss: 68.94998346481786\n-----\n t u h noSocr  se cel tare ptcwesg peur ris sme l  kti heedrercdietheei rm tytsegih w nanh s har cawedee  ?kpehes odut\"   the enshe w he rshaoonina  n afen l  o hiba ete - aH eolseessd ee fhee taego ae \n-----\niter: 48000 - loss: 69.2178549279071\n-----\n  i m(fea ugpegl fee p.eheyebo nhase  efnollrire n obes Gid reaah i t Geony   awinodr   hleee wesaege uer sn dly fr   ee el h se.ee noceme stuaorle nlir he we ty  s m, ln  e veataladome wale ,eih pe de \n-----\niter: 49000 - loss: 69.48131915939598\n-----\n p nee we wuo g a t eottw ;fwiws c erer id s yk ef n oin in,elete sl wde seee,d heire  Nana,n wo tede  r ananoaee H s rhe s nd r fe dvke  eeiee s  telee neineneo nb heis ier is haheenie  w ie ee lind f \n-----\niter: 50000 - loss: 68.11821154689177\n-----\n oood ree ngere vin  me ee anG ereeyte t eliir ioeele betere, geuenon yee n t se dd hepe uke  il he twe m  ire  r ev rhedie n neooin ct heseenrc  nj itiini su, sha e toei reneirtee nr h,lf h j simroge  \n-----\niter: 51000 - loss: 68.32971358607027\n-----\n e e teehexmeaee  a ss  tpeFihhitaera bin sisn   ew f aot sre e  we  o tse ta   ac hehe ihathse hem. mif )e ochehicn won s   eAsathe geral us .aintregr a e,d  b oh su l tir  hewrnr p  tme hehasen ams   \n-----\niter: 52000 - loss: 68.87067083070943\n-----\n he  uWae eimi s oe  nsshi he hearfen, he c shenee w bcd t dhei ao, no na nheribesd he d .e ane  uaieeuheleneG d sne af jnlelite hi l wt iestop ee heuereg   lotoveagi nd ere hepkttn wae cr wseeageer mh \n-----\niter: 53000 - loss: 69.86808672408533\n-----\n e oatnahmre anottrhentb g , d yin lleitta ihat ifhe oib rhlte a ed tnr eral  arela lan. wrheolhneg has c haneeit minsy seonmosee tee ar hane  e nsu aogeeie herj y ,he slet iehs  u  hefyeor whe sr uwcr \n-----\niter: 54000 - loss: 69.5499533692289\n-----\n esioIacois theow ros chepeltc ns mhet ckytheantleoc we he rHae. od nen kinrnrrwe hi k nyeaotsym w hatned gefkdoGfrvgne  Btosurittiinbn  naghat ba hyi  asasayed l hed nihe he s we ddan co﻿ hu thy geegn \n-----\niter: 55000 - loss: 69.26352219091235\n-----\n se hh od sene hhei, jslothea hiohounwps use ofwe wnife shlr m 'igoe.el whe henegna( hl y un  chin  ohhtosaxr dite ttetheonetww pe heesend n nidharn;  mhvj g  - d, h cle con edino nosue lheGiorl oetas  \n-----\niter: 56000 - loss: 69.10497981335023\n-----\n e hd MhoSe vog toein thethhes( gwasle  Gpohe n axt ce eg Ahe twe y f bnoe  feheoshie 'mnirreiButha\"e bhn  gn hto ceacu hed llet netoe   bhhanmeotrthewis wihesittenf,aslherttsving e hd S muwtte nertaoh \n-----\niter: 57000 - loss: 69.35780424323367\n-----\n  lheitsm camaliof silnd heh aehid e gt t anete rd f we ate;gt,det,d hha rermrne hh  fd t fai  tiocereleosinwnethen hcre orrdnasre ois oanc ee o on  sd r feot yioyn   u  susheoubgee, hanasis d nlehinav \n-----\niter: 58000 - loss: 70.42246704819004\n-----\n f t wncwhifH 'd t I Mt e n n nket og ti uto  eye hos hirtg  che foaoGeis     h fukinolmge oneye ne jbtme raheeps. gtoue  shoona  .tphe  sla sontdae oasileyurke gge hegg dhea  s ie  dabewe itetim fabof \n-----\niter: 59000 - loss: 69.74308796166875\n-----\n  to ta, neegeren oyeo hed  ha  sn n soyee mleir rvt s  reeeaa e tret f rhe s hei; rnee nhen mciieo  \nmm he f esg ae  r'e reçose aG  hen gheoh scear seerf nin aseas  w cce clrese ie  aanus  r  welarhei \n-----\niter: 60000 - loss: 69.9774841634962\n-----\n lerp oe onze t hinwioe n oo ntoe h oh no iguone hlyeis teinl aesdts tnle mg  aeg h se o u nh n oretlaatt\nire  o irbroouteg t Athe kp sbdenueeret z sardirhe istdle t phemd  Gfeau nduhekaree kee nge ner \n-----\niter: 61000 - loss: 69.65450256689688\n-----\n se   gee ahe  iog nsctce s itels Hgehue athe w lidins  nmte s raiton d n dei.e ad le a nese s ilene asB se t  n h    y iid teoohe m nrea  g eis ao s ,inr he igee s ha m esr gee n iwe s \neo  thf khee d \n-----\niter: 62000 - loss: 69.94092435375194\n-----\n \"et n titlhe  rdet ag n,eton as s  \"it-en tioesn en t  tag his wee\" n sin habe tare as t athe  Tw ge  ndihee  ee  he  thee npea a aslncei mheb . ee s ap nhea'wfi fe ard wheb.  athr dhed isas ahe neee  \n-----\niter: 63000 - loss: 69.61456667542943\n-----\n e  r rbe mriee whii he g Gnhieisce d the lft hd nek w uibs at l she  ehe nep fdrbe. ihe reg ad   roe  aoiegleen n o le   vhhirlihei t  damhe eawime d  ivio  s lei tnaaighehe n re as  , v hein wtese g  \n-----\niter: 64000 - loss: 68.48475460993987\n-----\n he rpltfe t cdeoes  t.teeottheeae   \nrooa s. re r ted thes cr  nagre l e nmhve le edr tehesin d bnaam  tsle  nd aahis thhmie bheeeoy   uthee , Tuhe dopnnme  tb aeaun wnnde  ssaheg pen she re e thhe ge \n-----\niter: 65000 - loss: 68.61911395242782\n-----\n oce hYke.e on  so.  nsfe brhealhathfGhe  Iheeeb, tae Lnihate hlrase \"çms s t hese thewaoceve stu  heone ahib che che n rm a mlmee baie gaathem i lsons naoatd c hele hedt her,.ahanet boreadom scsne  ah \n-----\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "iter: 66000 - loss: 68.2686441495432\n-----\n hea tea siupny heubh, hamoheoheIer niwe uke nhenhikiydeg bhem aw aheihot hetei en ehaoeeintOe i hind?aIvd b wt te e vnhethhewe h c l mesy eoun﻿ wc houseg dt thoe fhefe Gnele  ayainoCiv hewho.he w:  oG \n-----\niter: 67000 - loss: 69.37293681029556\n-----\n hereiir on h hei h lrg i le ois hhe f tf Gh hoee wifd naoeee w ude h., rto h lepelo ewe d f d bpmo ce fh P she os  cihe agf nutugede(mha  c  maye it . w  me annersher  e bir hsg uhe aeGve reoyp wy.eoa \n-----\niter: 68000 - loss: 69.75806034342062\n-----\n inst  c. afh, ke th kd oh  iislhewbtr ily ejg,e e n sf tuln : eosd lo winwe\n  Pels ncee lidof n sfus aced  a age tr,oso on mha ft n og okpe eu l be wnaahlwsoinndeootedecetrak eseab. \"ayetsge uedi ;ite \n-----\niter: 69000 - loss: 69.1252218124864\n-----\n aa sule t wmecoEeme medohon tr  linda us eee  tcree ley tlae heioeo r oc e tfalaehaewle scueQrslst w\"ce leIS dod pnyeh dkare eu dithn weleiubrneI c su  steowyeg  HaHds tjsr m mittoiyld ith t kos meyaf \n-----\niter: 70000 - loss: 68.77920803361172\n-----\n  edh \"e whte fdvu oe onedm aWjnGee fytoegs fuisheiufkm e Gnleaenlee  bnn fdheer tgeaagsdiee bn,ld eme ssl e elpfeeebmBme ro e d Sha aor euwfine ikeeai he tGi\nre Tld bu ge,e aldnr lemsseaehe eiiftea sn \n-----\niter: 71000 - loss: 69.20069840099761\n-----\n o h oto he uheehedhib'teudseeenesheiey m n\ndieatrkohe hceiosatiry erlwotiawn eaaadewe \"t nii eoiuteee oat e edegh,rchelhewimaehe heaaamne Gree  citiadtii nsoudele wgtrere itad'nhe d aerohdeiivhp dicav \n-----\niter: 72000 - loss: 69.8540798904491\n-----\n  weeroif brg ke baohhlroonndeithrmedeiJcee he i h,onu Gd oth he o eneMi ml cet feet Bigao anioen\npt e  we aee Hide f leh neciyaiabte,iee\"ngk t-eag uk   lmlhe heeeefte afhor eeeal weiis wh inyfot'f vee \n-----\niter: 73000 - loss: 68.26941560801791\n-----\n e eyheo  te w aiid toniri tae lu  aeud ehhoe heceoe he h; w ag e bat s iow  hhn rawor eeharad fatofeeeaSheohaelgte ahgu.e b me s aniehicue chemebhen e oue t hadl kolue thley sahd leut he bosedfapntil  \n-----\niter: 74000 - loss: 67.51825239453318\n-----\n e ime-p isibee  gooa eua l e he eioe\"Grls woc teean g ke tae  nr  cdsaxm lis Tognei Got  ran n gani tregpeohe  be tiierh,eea ik e hs oe\ndn.ut, wore og bini \nnet erod m wa ne o the ce nnde w hee, he na \n-----\niter: 75000 - loss: 67.53639361023333\n-----\n  we lati hnt  aeuo  bhah,eaoe ogia  whl re ooelibingI e nhassge ied  ale s fndhee bhe a theereted, heuh ithaee he nnoee bbe.  bae iiteadesarhhseisee s cheo Gt lylhoilghe uade ihetiged helisheiwot wotf \n-----\niter: 76000 - loss: 68.66168085820851\n-----\n nisa adm d   nhe  rhon, iw f 'k hsgow opl ctuyeeefrave powJ   wj tr,isoveeiHnydehn h'e ehewe ehas taae\nais- w.ehe di ishoc ti in tdeftr ufnhtess aasie het thbeWoteehe saohehaootanet   w t ,fapDi bt Gd \n-----\niter: 77000 - loss: 70.07038309919209\n-----\n naeh\" nhstinuwe iafhreue in relthigie;on irehbhe ovey  hio  nanhnpa ash s molengeaoedle ya  f.onotmterivd l \"ntoiaee an  o .ot .itei ehegyr tesesueit hmor fe Ieild ik fih   il lithsg owe,aeouun hee na \n-----\niter: 78000 - loss: 69.75633747438849\n-----\n heihe eheg hegd Qdheknlusmno'nuoutos esigo t eee os vebe  lenhriter petrahe t t th sf bs   st. auhrtu raohgoho  the  otieebeahtre.rre eH  d ges tao hateg ik teett  lko iceiswy nd ochok. n ai leg Timhe \n-----\niter: 79000 - loss: 69.36581945835842\n-----\n   ilhe isi ba he ne,eWeeifnn ee he cohio  aineeitarpcijh kthH yie flyiee.e tro mi aenso,owdeexan tr i dls tng hohe he tpceuuun an aee tpeeay s n le iee  nto ,ohehheite eoshanai te the rer    ao ehy ss \n-----\niter: 80000 - loss: 69.19647458800736\n-----\n eo vin aatru in mddo he he etag bsra geriu eo, hte p leaoe lae Gugeolha\nerreiniawoohs.te rgl ma, oroioerldeen wedener thb,eooo meg mpe thisseaalede Og nis,feto titet fcddosnteiw Aism uia krdt opoe un. \n-----\niter: 81000 - loss: 69.91659394644176\n-----\n iteuntweointi ta stintine ?neeoi nu elro me sieo dlehe odeolrG it\"l l tini tt tisto. tu a aslg aertyivegt eunoHie  cA r s illh yeo   ee meys lsm.e uxn, wg.ed n w  Wgisit\"cmo tnod h nheau ,  aeHs hehe  \n-----\niter: 82000 - loss: 70.02072978815418\n-----\n o tnik )nkh ee ege  W e sihh e ; wgeis. o Haware: he exhiee s neisttegibdi e wnc lleuairgWeegrheIhm eth o\"sle celo Mtt tof  hare aoheaamhha tt,  iw on'athe holatec h f g tnyegh s pi ltuweehe  s hetdee \n-----\niter: 83000 - loss: 69.20348303435068\n-----\n  ifcisoueve,, te  adve pchinley sule  lapeethaecss aits r'a neevee hocl,   eneik own,nabi,ghltheit nescwhe lisy  hsacb a,l n aofrutdy  rl, rhew beinhiaait,k  sh tc n theeeineuveet tot ith   iwgy r Uat \n-----\niter: 84000 - loss: 69.26067368309829\n-----\n  mtnfeoube  h  hesuguiodaca,hiheode euioHohi ,oresimcdlirha he g ghe orhaalv bith gi a hen,, eeelacaf dahe nitrlt wwan nhoea pie si ap aweawle s woe heo aBoluisd emin ghire isiwe heneirndehivterw vihh \n-----\niter: 85000 - loss: 69.36807217937539\n-----\n he,o aeveei e  g nrtasotge g e broelld nyd hijnsacber et aodetowe eoch se, t r hoofins  sb\nea hhisg hyoek voanofihe ro,  wod ,d yeeo th\no  aerlhett  e elathenant ney rngte e f eylhIeinehenkimeog \"eedh \n-----\niter: 86000 - loss: 69.90250856236479\n-----\n oeerndt ww nf at,, fty ekdr  hehiceawBoeae rfueto td ia\niro wefidhent eute;eahe﻿ee rD t ek.usasn bilsta b ker, w   lmowta trw tl ts d  he m nn nbaoreence midit s ?ith is Teaketer   otl trln ohevsd Tos \n-----\niter: 87000 - loss: 70.00030341740363\n-----\n  e dpaeis tdias r,ehit is (gyemdoeoo s e t wd ho te, soepe eouhegae orkhpared beh ele fgt   ht gelnve  afdoe pmeennnnde, hh y dos tihided nimeniliksra t\"f,'n l srnoGe uuditim, ar\ne ttoiad tdahe preod  \n-----\niter: 88000 - loss: 69.56885039655634\n-----\n b  nmanetht, pe'i he ub bo ovelaeh  n,erol  stlaeenahon, bt  r  ct t n theean ee ron, mad le\" bndas s nnes,d gorha ettiGtmbrGu,heg a.  f pe hs aeslaansi Gneorepasle.satsiegoay ewri t onowetnt erao t,  \n-----\niter: 89000 - loss: 69.83099641569312\n-----\n s aifoleozsowu reo rscadin n a oott  nthe yten ttk,'hirr  dave n th ont t Sisond d  kee!ndonir seabn, \norll vagdan. towin  r ;nera osgaoha etoo iitl Nt eetd Uoh fhet  g iade   et. nnyesa acG  odan ,er \n-----\niter: 90000 - loss: 70.28823241039473\n-----\n yr rn,af eita,  aanl eiaeyd ondded  unhene f, btee,Ghedeolshe gh e hertasun, bnedltum atayd  usp adpeye md daeoh onssaciele mrMiiteleu  t gouktnwdemamsao t tett rtelfhooulng w, fei ch trunraeehao) h n \n-----\niter: 91000 - loss: 71.1846049522764\n-----\n nagibnwn rt aswsthoe glorl rreBarpimhes terw cwea itatelrs gt.en wehemsomm ahokctl vandcan  nmhhogatwharaviCJaltdoas ielliniIf, tnhuec r onr wds tieko ell  r,ot\". sdhluhre emnisinoir ubdstarher  otot, \n-----\niter: 92000 - loss: 70.20575153065228\n-----\n t of pcteepwmahedeateathd need n nersa  is oiowiGk  isetne meenweiwOo ix lhcone cbm uwl sbedone  himoiest ins tetetwkhe manle eseeakt.a  sd. inssdd oouo haeh sleaun onaeoiof'a'lle fnim or hlher ha.her \n-----\niter: 93000 - loss: 69.77063289373598\n-----\n thsinrtee dwttsisçteeetn sr heootteonwot ris vesn  wrf ghamherpeu\nstes odiDtgoitntiod ns s, le,cf h tmemng h antesof. tertyd wlnm t haheher teauprapoorigd soelm we e ieu she mn aoer cvo aeriua owa nio \n-----\niter: 94000 - loss: 69.35259376899516\n-----\n trrale thy ns tefve aacce t rem nsas Cu odg \" hoaunmgaotittie wen ale heyeinhw th mnawe teth fu tle detlei te riatoisoct m hlely e emna\nr,s tee w heleehefteakeurnarom,c f,esim tie rr pe L ihe ouftoae  \n-----\niter: 95000 - loss: 69.92659177190458\n-----\n eniotset rtoatuee soay lihisf n sne wama. thereiep  t s  iAhtt ousikasbeut oodto won adhy  weme moob ne he tir mo tcae blin idfhmfn s sne t vt teenaaeugm nilohh hreeagBmaedeheagy iB fs gs ubet 'otor i \n-----\niter: 96000 - loss: 70.66111739980846\n-----\n \" tnutkonne  x fa ieshen voocleaowid yesritpon eb ah tedevveeadl wtad Hara.ngoieorhador stib s isy m saletzthe gh oaybenonsu afag  ets e\nn  erl noaicwtnayittbnpegmttia o hdd. ealres wtrer  db suti ptl \n-----\niter: 97000 - loss: 70.0239671689812\n-----\n enwoo w. er\nseAcszse hrlale rh  t mtusisnemlnoWcelej  si  eollee(rlmng aref Hiohe vit  webi!iadnice \nnolo t deeegtheer sonve ,ora, an  t im nl t du ss tncesslos bSv  fit  v;drteg  rat tn.giu tselinnnd \n-----\niter: 98000 - loss: 69.93548703344378\n-----\n efoT eriouerjhi\"nyahe r,  ed e. t d \"ldaarykeis hacthe   bnldo eurseru\nenn l\" et imtpfihead pt e n eonr  rot Gatuldek  asreylsie kta eesearGtobthim osdp\nwour  , rtnrt \"dooinlb  odsaugtnobin asoaenaeer \n-----\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "iter: 99000 - loss: 69.70241597982422\n-----\n i  vefdtyerylli  bi cet' hloacr rteeyahebe e neme'Gtisiyhe h ind noertad d se  romtiah \"ot hhe;ig bttrineiegy wn bec  s hhnsetntohun nsrieocreHtate r hhldinna eimclwe nmoinpye t  heeenwweo td Lr pdisw \n-----\niter: 100000 - loss: 70.62401572999133\n-----\n nm yo g'wmeunldo\"iYheont de akonaue etqewec tds ley t rseo eihd vndeiy etdosae i toIions'tho wwmsmg t miw ssuras apionhe fati,ndOowermeshaiheGereqopieouhelyehe sofw onueytee beannthareln.lieser vmdtha \n-----\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "486a3f759bf866ace785e1be899e4fd5000f25c3"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0498b9ea03fd9c25f6c304c60f771e1a1951b388"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e3f51b25c2910e282a328865f4a22f98ae054ad"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2beac2a075acc494a1b1ec0a018dda47f231de5"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b3f6fa7540f3a27fddb62ea450c36f7705e3aeeb"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5043a3dd4d6af22812f12812a4a876fc13a11651"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db53bd2ba450a6e1485343f4de3aed173aac8c31"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}