{
  "cells": [
    {
      "metadata": {
        "_uuid": "c71b0e965d7ae417a7a9d30d5ce8c79ee25b3821"
      },
      "cell_type": "markdown",
      "source": "# 《Hands-On Machine Learning with Scikit-Learn&TensorFlow》\n\n## -  Chapter 14. Recurrent Neural Networks\n\n-----"
    },
    {
      "metadata": {
        "_uuid": "71c4b4d68329fced194b242ac247873303525bb5"
      },
      "cell_type": "markdown",
      "source": "# 1. RNN"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6d6692b524c6f934477ae29195b93fef3e7d3c2"
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nimport numpy as np\nfrom tensorflow.contrib.layers import fully_connected\n# tf.set_random_seed(1)",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e151daea3519e424854966d23ae74e8f70fa894"
      },
      "cell_type": "code",
      "source": "tf.reset_default_graph()",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1000d202134ad01a0fd589f9dbf00b6a136119f0"
      },
      "cell_type": "code",
      "source": "n_steps = 28\nn_inputs = 28\nn_neurons = 150\nn_outputs = 10\nlearning_rate = 0.001",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e0883ace44739c95e9d736cb3ef3011bb97d6dc"
      },
      "cell_type": "code",
      "source": "x = tf.placeholder(tf.float32, (None, n_steps, n_inputs))\ny = tf.placeholder(tf.int32, (None,))",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d716b2d6db6927750e8da262fbf5f8bf064a3e45"
      },
      "cell_type": "code",
      "source": "class DeviceCellWrapper(tf.contrib.rnn.RNNCell):\n    def __init__(self, device, cell):\n        self._cell = cell\n        self._device = device\n    @property\n    def state_size(self):\n        return self._cell.state_size\n    @property\n    def output_size(self):\n        return self._cell.output_size\n    def __call__(self, inputs, state, scope=None):\n        with tf.device(self._device):\n            return self._cell(inputs, state, scope)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e446c5b6be89bbf6f699bf39da8d57fc3fc08fea"
      },
      "cell_type": "markdown",
      "source": "## GPU\n```python\ndevices = [\"/gpu:0\", \"/gpu:1\", \"/gpu:2\"]\ncells = [DeviceCellWrapper(dev,tf.contrib.rnn.BasicRNNCell(num_units=n_neurons))\nfor dev in devices]\nmulti_layer_cell = tf.contrib.rnn.MultiRNNCell(cells)\noutputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n```"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc2b76e622a4b4aadb5268d635be4b22f77aa6a9"
      },
      "cell_type": "code",
      "source": "cells = DeviceCellWrapper(\"/gpu:0\",tf.contrib.rnn.BasicRNNCell(num_units=n_neurons))\noutputs, states = tf.nn.dynamic_rnn(cells, x, dtype=tf.float32)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e397099283d4cba4c6aa379b49e73fde250e50e"
      },
      "cell_type": "code",
      "source": "# basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n# outputs, states = tf.nn.dynamic_rnn(cell=basic_cell, inputs=x, dtype=tf.float32)\n\nlogits = fully_connected(inputs=states, num_outputs=n_outputs, activation_fn=None)\ncross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n\nloss = tf.reduce_mean(cross_entropy)\n\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_operation = optimizer.minimize(loss)\n\ncorrect = tf.nn.in_top_k(logits,y,1)\naccuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n\ninit = tf.global_variables_initializer()",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9b8c0a21a6def9d426337e9013206f3b20e1900f"
      },
      "cell_type": "markdown",
      "source": "## tf.fully_connected()\ncontains initialization of iniform weights and zero bias.\n```\ntf.contrib.layers.fully_connected(\n    inputs,\n    num_outputs,\n    activation_fn=tf.nn.relu,\n    normalizer_fn=None,\n    normalizer_params=None,\n    weights_initializer=initializers.xavier_initializer(),\n    weights_regularizer=None,\n    biases_initializer=tf.zeros_initializer(),\n    biases_regularizer=None,\n    reuse=None,\n    variables_collections=None,\n    outputs_collections=None,\n    trainable=True,\n    scope=None\n)\n```\n1. **weights_initializer=initializers.xavier_initializer()**\n```\ntf.contrib.layers.xavier_initializer(\n    uniform=True,\n    seed=None,\n    dtype=tf.float32\n)\n```\n2. ** biases_initializer=tf.zeros_initializer()**\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "710d33fb8d55d3b16e8c9e62ebe9ef51ca9bc5e1"
      },
      "cell_type": "code",
      "source": "from tensorflow.examples.tutorials.mnist import input_data",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5033c4dc4af4f84ed6423ae3e82d4eed0222a59a"
      },
      "cell_type": "code",
      "source": "mnist = input_data.read_data_sets('mnist')\nx_test = mnist.test.images.reshape((-1,n_steps,n_inputs))\ny_test = mnist.test.labels",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting mnist/train-images-idx3-ubyte.gz\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting mnist/train-labels-idx1-ubyte.gz\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting mnist/t10k-images-idx3-ubyte.gz\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting mnist/t10k-labels-idx1-ubyte.gz\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef2e22355952ba499979d84a0f7ea1387382e9d0"
      },
      "cell_type": "code",
      "source": "n_epochs = 100\nbatch_size = 150\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        for iteration in range(mnist.train.num_examples//batch_size):\n            x_batch, y_batch = mnist.train.next_batch(batch_size)\n            x_batch = x_batch.reshape((-1,n_steps,n_inputs))\n            sess.run(training_operation, feed_dict={x:x_batch, y:y_batch})\n        acc_train = accuracy.eval(feed_dict={x:x_batch, y:y_batch})\n        acc_test = accuracy.eval(feed_dict={x:x_test, y:y_test})\n        print('{} epoch, Train accuracy: {:.3f} - Test accuracy: {:.3f}'.format(epoch, acc_train, acc_test))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0 epoch, Train accuracy: 0.927 - Test accuracy: 0.920\n1 epoch, Train accuracy: 0.973 - Test accuracy: 0.950\n2 epoch, Train accuracy: 0.947 - Test accuracy: 0.959\n3 epoch, Train accuracy: 0.973 - Test accuracy: 0.958\n4 epoch, Train accuracy: 0.987 - Test accuracy: 0.965\n5 epoch, Train accuracy: 0.973 - Test accuracy: 0.965\n6 epoch, Train accuracy: 0.980 - Test accuracy: 0.971\n7 epoch, Train accuracy: 0.980 - Test accuracy: 0.971\n8 epoch, Train accuracy: 0.973 - Test accuracy: 0.960\n9 epoch, Train accuracy: 0.987 - Test accuracy: 0.972\n10 epoch, Train accuracy: 0.993 - Test accuracy: 0.970\n11 epoch, Train accuracy: 0.980 - Test accuracy: 0.969\n12 epoch, Train accuracy: 0.993 - Test accuracy: 0.969\n13 epoch, Train accuracy: 0.987 - Test accuracy: 0.976\n14 epoch, Train accuracy: 0.967 - Test accuracy: 0.974\n15 epoch, Train accuracy: 0.993 - Test accuracy: 0.976\n16 epoch, Train accuracy: 0.960 - Test accuracy: 0.965\n17 epoch, Train accuracy: 0.953 - Test accuracy: 0.973\n18 epoch, Train accuracy: 0.987 - Test accuracy: 0.975\n19 epoch, Train accuracy: 0.993 - Test accuracy: 0.971\n20 epoch, Train accuracy: 0.993 - Test accuracy: 0.977\n21 epoch, Train accuracy: 0.993 - Test accuracy: 0.975\n22 epoch, Train accuracy: 0.973 - Test accuracy: 0.975\n23 epoch, Train accuracy: 0.987 - Test accuracy: 0.970\n24 epoch, Train accuracy: 0.993 - Test accuracy: 0.971\n25 epoch, Train accuracy: 0.987 - Test accuracy: 0.975\n26 epoch, Train accuracy: 0.993 - Test accuracy: 0.979\n27 epoch, Train accuracy: 0.980 - Test accuracy: 0.969\n28 epoch, Train accuracy: 0.973 - Test accuracy: 0.981\n29 epoch, Train accuracy: 0.993 - Test accuracy: 0.975\n30 epoch, Train accuracy: 0.987 - Test accuracy: 0.979\n31 epoch, Train accuracy: 0.967 - Test accuracy: 0.972\n32 epoch, Train accuracy: 0.980 - Test accuracy: 0.977\n33 epoch, Train accuracy: 0.993 - Test accuracy: 0.978\n34 epoch, Train accuracy: 0.987 - Test accuracy: 0.979\n35 epoch, Train accuracy: 1.000 - Test accuracy: 0.975\n36 epoch, Train accuracy: 1.000 - Test accuracy: 0.980\n37 epoch, Train accuracy: 1.000 - Test accuracy: 0.971\n38 epoch, Train accuracy: 0.993 - Test accuracy: 0.981\n39 epoch, Train accuracy: 1.000 - Test accuracy: 0.981\n40 epoch, Train accuracy: 0.987 - Test accuracy: 0.978\n41 epoch, Train accuracy: 1.000 - Test accuracy: 0.978\n42 epoch, Train accuracy: 0.993 - Test accuracy: 0.980\n43 epoch, Train accuracy: 0.993 - Test accuracy: 0.977\n44 epoch, Train accuracy: 0.987 - Test accuracy: 0.981\n45 epoch, Train accuracy: 0.987 - Test accuracy: 0.975\n46 epoch, Train accuracy: 0.993 - Test accuracy: 0.978\n47 epoch, Train accuracy: 0.993 - Test accuracy: 0.979\n48 epoch, Train accuracy: 0.993 - Test accuracy: 0.979\n49 epoch, Train accuracy: 0.993 - Test accuracy: 0.979\n50 epoch, Train accuracy: 0.993 - Test accuracy: 0.980\n51 epoch, Train accuracy: 0.980 - Test accuracy: 0.974\n52 epoch, Train accuracy: 0.987 - Test accuracy: 0.973\n53 epoch, Train accuracy: 0.993 - Test accuracy: 0.980\n54 epoch, Train accuracy: 0.993 - Test accuracy: 0.981\n55 epoch, Train accuracy: 1.000 - Test accuracy: 0.978\n56 epoch, Train accuracy: 1.000 - Test accuracy: 0.980\n57 epoch, Train accuracy: 1.000 - Test accuracy: 0.979\n58 epoch, Train accuracy: 1.000 - Test accuracy: 0.980\n59 epoch, Train accuracy: 1.000 - Test accuracy: 0.976\n60 epoch, Train accuracy: 0.987 - Test accuracy: 0.979\n61 epoch, Train accuracy: 0.987 - Test accuracy: 0.977\n62 epoch, Train accuracy: 0.993 - Test accuracy: 0.973\n63 epoch, Train accuracy: 1.000 - Test accuracy: 0.977\n64 epoch, Train accuracy: 1.000 - Test accuracy: 0.979\n65 epoch, Train accuracy: 1.000 - Test accuracy: 0.981\n66 epoch, Train accuracy: 0.987 - Test accuracy: 0.979\n67 epoch, Train accuracy: 0.980 - Test accuracy: 0.968\n68 epoch, Train accuracy: 0.987 - Test accuracy: 0.972\n69 epoch, Train accuracy: 1.000 - Test accuracy: 0.974\n70 epoch, Train accuracy: 0.987 - Test accuracy: 0.978\n71 epoch, Train accuracy: 1.000 - Test accuracy: 0.982\n72 epoch, Train accuracy: 0.987 - Test accuracy: 0.965\n73 epoch, Train accuracy: 0.993 - Test accuracy: 0.975\n74 epoch, Train accuracy: 0.993 - Test accuracy: 0.976\n75 epoch, Train accuracy: 1.000 - Test accuracy: 0.978\n76 epoch, Train accuracy: 0.980 - Test accuracy: 0.967\n77 epoch, Train accuracy: 1.000 - Test accuracy: 0.980\n78 epoch, Train accuracy: 0.987 - Test accuracy: 0.978\n79 epoch, Train accuracy: 0.993 - Test accuracy: 0.971\n80 epoch, Train accuracy: 1.000 - Test accuracy: 0.977\n81 epoch, Train accuracy: 0.993 - Test accuracy: 0.978\n82 epoch, Train accuracy: 1.000 - Test accuracy: 0.979\n83 epoch, Train accuracy: 0.993 - Test accuracy: 0.979\n84 epoch, Train accuracy: 1.000 - Test accuracy: 0.978\n85 epoch, Train accuracy: 0.973 - Test accuracy: 0.978\n86 epoch, Train accuracy: 0.980 - Test accuracy: 0.979\n87 epoch, Train accuracy: 0.993 - Test accuracy: 0.978\n88 epoch, Train accuracy: 1.000 - Test accuracy: 0.980\n89 epoch, Train accuracy: 1.000 - Test accuracy: 0.978\n90 epoch, Train accuracy: 0.980 - Test accuracy: 0.967\n91 epoch, Train accuracy: 0.987 - Test accuracy: 0.979\n92 epoch, Train accuracy: 1.000 - Test accuracy: 0.980\n93 epoch, Train accuracy: 0.987 - Test accuracy: 0.979\n94 epoch, Train accuracy: 0.993 - Test accuracy: 0.979\n95 epoch, Train accuracy: 0.980 - Test accuracy: 0.979\n96 epoch, Train accuracy: 0.993 - Test accuracy: 0.978\n97 epoch, Train accuracy: 0.993 - Test accuracy: 0.978\n98 epoch, Train accuracy: 1.000 - Test accuracy: 0.978\n99 epoch, Train accuracy: 0.993 - Test accuracy: 0.981\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f67f27d9dcc0a8ed7051c353f6cd998fa6febb9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c8eab7829304a1438fb14e63dc61833a77b42930"
      },
      "cell_type": "markdown",
      "source": "# 2. Mofan's LSTM\n[https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tf20_RNN2/full_code.py](https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tf20_RNN2/full_code.py)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bcb0be7325bfd8abce5ff186608605c64a9f50d6"
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\ntf.reset_default_graph()\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3055bd83a7dcd45a39f693065c5279ed588dd44"
      },
      "cell_type": "code",
      "source": "lr = 0.001\ntraining_iters = 100000\nbatch_size = 128",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "899a14b54b7dc800778d48c79a1e945e7f105cf0"
      },
      "cell_type": "code",
      "source": "n_steps = 28 # each sentence has 28 time steps/ words\nn_inputs = 28 # input vector for each timestep/ lstm cell\nn_hidden_units = 128\nn_classes = 10",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9da51d9dbe47dbc2e7b9743daa52c8f51fe5dc77"
      },
      "cell_type": "code",
      "source": "x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\ny = tf.placeholder(tf.float32, {None, n_classes})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b18939bd350fbd9c79275253295f41d4aef1cf58"
      },
      "cell_type": "code",
      "source": "weights = {\n    'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),\n    'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))\n}\nbiases = {\n    'in': tf.Variable(tf.constant(0.1, shape=(n_hidden_units,))),\n    'out': tf.Variable(tf.constant(0.1, shape=(n_classes,)))\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd6b9d1de22daa8a6611bd82c3f3446b3e4b6e07"
      },
      "cell_type": "code",
      "source": "def RNN(x, weights, biases):\n    # (128batch, 28time step, 28inputs) -> (128*28, 28inputs)\n    x = tf.reshape(x, [-1,n_inputs])\n    x_in = tf.matmul(x, weights['in']) + biases['in']\n    x_in = tf.reshape(x_in, [-1, n_steps, n_hidden_units])\n    \n    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)\n    # state_is_tuple (last memory, last output), c[t-1], h[t-1]\n    \n    _init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)    \n    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x_in, initial_state=_init_state, time_major=False)\n    \n    results = tf.matmul(states[1], weights['out']) + biases['out']    \n    return results",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b2ac85e293c67b8eaa2babf1b6736e646c051448"
      },
      "cell_type": "markdown",
      "source": "## LSTM cell\n```python\ntf.nn.rnn_cell.BasicLSTMCell(num_units, forget_bias=1.0, state_is_tuple=True, activation=None, reuse=None, name=None, dtype=None, **kwargs)\n```\n```python\ntf.nn.dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)\n```"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2d72025b40c15a750e23aa16ce9ef0fbdcb014d9"
      },
      "cell_type": "code",
      "source": "pred = RNN(x, weights, biases)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\ntrain_op = tf.train.AdamOptimizer(lr).minimize(cost)\n\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\ninit = tf.initialize_all_variables()\nwith tf.Session() as sess:        \n    sess.run(init)\n    step = 0\n    while step * batch_size < training_iters:\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        batch_xs = batch_xs.reshape([batch_size, n_inputs, n_steps])\n        sess.run(train_op, feed_dict={x:batch_xs, y:batch_ys})\n        if step % 20 ==0:\n            print(sess.run(accuracy, feed_dict={x:batch_xs, y:batch_ys}))\n        step += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "12c221e867e8431d19b25ca08cd99026c5de27da"
      },
      "cell_type": "markdown",
      "source": "# 3. aymericdamien/TensorFlow-Examples\n[https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "128f0c22aa23a6e8fe0a54ab545c95ab2ee9d3e2"
      },
      "cell_type": "code",
      "source": "from __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib import rnn\ntf.reset_default_graph()\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n\n'''\nTo classify images using a recurrent neural network, we consider every image\nrow as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\nhandle 28 sequences of 28 steps for every sample.\n'''\n\n# Training Parameters\nlearning_rate = 0.001\ntraining_steps = 10000\nbatch_size = 128\ndisplay_step = 200\n\n# Network Parameters\nnum_input = 28 # MNIST data input (img shape: 28*28)\ntimesteps = 28 # timesteps\nnum_hidden = 128 # hidden layer num of features\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(\"float\", [None, timesteps, num_input])\nY = tf.placeholder(\"float\", [None, num_classes])\n\n# Define weights\nweights = {\n    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n}\nbiases = {\n    'out': tf.Variable(tf.random_normal([num_classes]))\n}\n\n\ndef RNN(x, weights, biases):\n\n    # Prepare data shape to match `rnn` function requirements\n    # Current data input shape: (batch_size, timesteps, n_input)\n    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n\n    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n    x = tf.unstack(x, timesteps, 1)\n\n    # Define a lstm cell with tensorflow\n    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n\n    # Get lstm cell output\n    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n\n    # Linear activation, using rnn inner loop last output\n    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n\nlogits = RNN(X, weights, biases)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, training_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Reshape data to get 28 seq of 28 elements\n        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y})\n            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.3f}\".format(acc))\n\n    print(\"Optimization Finished!\")\n\n    # Calculate accuracy for 128 mnist test images\n    test_len = 128\n    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n    test_label = mnist.test.labels[:test_len]\n    print(\"Testing Accuracy:\", \\\n        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef0b59d27939475e736e764f197637cdf6ea741e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b90d0e3205cf66204c33f04de5d4bad9933b8c2"
      },
      "cell_type": "markdown",
      "source": "1. Init a tf  tensor\n\n```python\ntf.InteractiveSession()\n\na = tf.constant([[[1,2,3],[4,5,6]],[[7,8,9],[0,1,2]],[[3,4,5],[6,7,8]]])\nprint(a.shape)\na.eval()\n```\n[out]:\n\n```\n(3, 2, 3)\narray([[[1, 2, 3],\n        [4, 5, 6]],\n\n       [[7, 8, 9],\n        [0, 1, 2]],\n\n       [[3, 4, 5],\n        [6, 7, 8]]], dtype=int32)\n```\n2. tf.transpose(a, perm=None, name='transpose', conjugate=False)\n\n change the shape by origin position idx through perm\n\n```python\nb = tf.transpose(a, perm=[1,0,2])   \nprint(b.shape)\nb.eval()\n```\n[out]:\n\n```\n(2, 3, 3)\narray([[[1, 2, 3],\n        [7, 8, 9],\n        [3, 4, 5]],\n\n       [[4, 5, 6],\n        [0, 1, 2],\n        [6, 7, 8]]], dtype=int32)\n```\n3. tf.unstack(value, num=None, axis=0, name='unstack')\n\n```python\nc = tf.unstack(b)\nfor i in c:\n    print(i.eval(),'\\n-----')\n```\n[out]:\n\n```\n[[1 2 3]\n [7 8 9]\n [3 4 5]] \n-----\n[[4 5 6]\n [0 1 2]\n [6 7 8]] \n-----\n```\n-----\n\n**All-in-one**\n```python\nx = tf.reshape(a, [-1, 3])\nx.eval()\n```\n[out]:\n\n```\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9],\n       [0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]], dtype=int32)\n```\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a084b8de5d294b4d82b673bd89220b0b8a972dd"
      },
      "cell_type": "code",
      "source": "\ntf.InteractiveSession()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3a72fd2d356dc22c92a59f60f3f7e0eec0ccbdf"
      },
      "cell_type": "code",
      "source": "a = tf.constant([[[1,2,3],[4,5,6]],[[7,8,9],[0,1,2]],[[3,4,5],[6,7,8]]])\nprint(a.shape)\na.eval()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "befa228b939f6a98d57f71349f90fa443589c336",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "b = tf.transpose(a, perm=[1,0,2])\nprint(b.shape)\nb.eval()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0390d025d906e66926e102db65ccb77078720d0a"
      },
      "cell_type": "code",
      "source": "c = tf.unstack(b)\nfor i in c:\n    print(i.eval(),'\\n-----')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4472db2dbf374629fa977bae74decc0700cf0086"
      },
      "cell_type": "code",
      "source": "x = tf.unstack(a, 2, 1)\nfor i in x:\n    print(i.eval(),'\\n-----')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1ebf9003a6e12527e4b2493c4f9bdd2ae7bc59d"
      },
      "cell_type": "code",
      "source": "x = tf.reshape(a, [-1, 3])\nx.eval()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ff267957631a5a0eab5c3ba4afd5bfb25536b3e8"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90bc5a092fc45e6a7892bcb9050f93101854e11e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98c553ca1c7e2b6d8b0753f3ae00a58be846999a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1b2c3b0eaa1da31c39bdc60158587ca8b94a3ed"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}